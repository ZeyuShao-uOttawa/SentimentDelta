# SentimentDelta - Simple Stock Market Analysis

A simple, clean Python toolkit for stock data processing and news scraping. Built with simplicity in mind.

## ğŸš€ Features

- **Simple Design**: Clean, easy-to-understand code
- **Stock Data**: Download and process stock data from Yahoo Finance
- **News Scraping**: Scrape financial news with embeddings
- **MongoDB**: Simple database operations
- **Logging**: Consistent logging throughout (no print statements!)
- **Configurable**: Environment variable support

## ğŸ“ Structure

```
sentiment_delta/
â”œâ”€â”€ config/config.py           # Simple configuration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py              # Simple logging
â”‚   â””â”€â”€                        # 
â”œâ”€â”€ db/
â”‚   â””â”€â”€ database.py            # MongoDB operations
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processor.py           # Stock data processing
â”‚   â””â”€â”€ scraper.py             # News scraping
â””â”€â”€ main.py                    # Main entry point
```

## âš¡ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export MONGODB_URI="your_mongodb_uri"
export TICKERS="AAPL,GOOGL,MSFT"

# Run stock data pipeline
python main.py

# Run news scraping
python main.py scrape
```

## ğŸ”§ Simple Usage

```python
from sentiment_delta import get_config, get_logger, create_mongodb_manager
from sentiment_delta.data import process_ticker_data

# Basic usage
config = get_config()
logger = get_logger(__name__)
data = process_ticker_data('AAPL')
logger.info(f"Got {len(data)} records for AAPL")

# Database operations
db = create_mongodb_manager(config.mongodb_uri, config.database_name)
db.create_document('my_collection', {'ticker': 'AAPL', 'price': 150})
```

## âš™ï¸ Configuration

| Variable      | Description             | Default              |
| ------------- | ----------------------- | -------------------- |
| `MONGODB_URI` | MongoDB connection      | Development URI      |
| `TICKERS`     | Comma-separated tickers | `AAPL,GOOGL,MSFT...` |
| `LOG_LEVEL`   | Logging level           | `INFO`               |
| `BATCH_SIZE`  | Database batch size     | `1000`               |

## ğŸ“Š What It Does

### Stock Data Pipeline

- Downloads hourly stock data for configured tickers
- Cleans and processes the data
- Stores in MongoDB (one collection per ticker)
- Logs all operations

### News Scraping Pipeline

- Scrapes financial news articles
- Extracts content and creates embeddings
- Stores in MongoDB with vector search support
- Logs progress and results

## ğŸ¯ Key Simplifications

- **No Print Statements**: Logger everywhere for clean output
- **Simple Functions**: No complex classes, just functions
- **Minimal Config**: Just the essentials
- **Clear Logging**: Consistent logging across all modules
- **Easy Imports**: Simple module structure
- **Less Code**: Removed complexity, kept functionality

This simplified version maintains core functionality while being much easier to understand and modify!

A clean, modular Python toolkit for stock data processing and sentiment analysis. Built with DRY and KISS principles for maximum reusability and maintainability.

## ğŸš€ Features

- **Modular Architecture**: Clean separation of concerns with reusable components
- **Stock Data Processing**: Download and process stock data from Yahoo Finance
- **News Scraping**: Scrape financial news articles with sentiment analysis
- **MongoDB Integration**: Unified database operations with vector search support
- **Configurable Logging**: Centralized logging across all modules
- **Environment Support**: Configuration via environment variables
- **Easy Integration**: Import utilities into other projects

## ğŸ“ Project Structure

```
sentiment_delta/
â”œâ”€â”€ __init__.py                  # Main package exports
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py             # Configuration management
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py               # Reusable logging utility
â”‚   â””â”€â”€ database.py             # MongoDB operations
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ processor.py            # Stock data processing
â”‚   â””â”€â”€ scraper.py              # News scraping
â”œâ”€â”€ main.py                     # Main orchestration
â”œâ”€â”€ setup.py                    # Package installation
â””â”€â”€ requirements.txt            # Dependencies
```

## âš¡ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Or install as a package
pip install -e .
```

### Basic Usage

```python
# Stock data processing
from sentiment_delta.data import process_ticker_data
from sentiment_delta.config import get_config

config = get_config()
stock_data = process_ticker_data('AAPL')
```

### Configuration

Set environment variables or modify config:

```bash
export MONGODB_URI="your_mongodb_connection_string"
export TICKERS="AAPL,GOOGL,MSFT"
export LOG_LEVEL="DEBUG"
```

### Running the Pipeline

```bash
# Run stock data pipeline
python main.py

# Run news scraping pipeline
python main.py scrape
```

## ğŸ”§ Module Usage Examples

### Configuration Management

```python
from sentiment_delta.config import get_config, create_config

# Use global config
config = get_config()
tickers = config.tickers

# Create custom config
custom_config = create_config({
    "TICKERS": ["AAPL", "GOOGL"],
    "BATCH_SIZE": 500
})
```

### Logging

```python
from sentiment_delta.utils import get_logger, log_operation_start

logger = get_logger(__name__)
log_operation_start(logger, "processing data", ticker="AAPL")
```

### Database Operations

```python
from sentiment_delta.utils import create_mongodb_manager

db_manager = create_mongodb_manager(uri, db_name)
db_manager.create_document('collection', data)
results = db_manager.vector_search('collection', 'query text')
```

### Stock Data Processing

```python
from sentiment_delta.data import process_multiple_tickers

results = process_multiple_tickers(['AAPL', 'GOOGL'])
for ticker, data in results.items():
    if data is not None:
        print(f"{ticker}: {len(data)} records")
```

### News Scraping

```python
from sentiment_delta.data import scrape_ticker_news

articles = scrape_ticker_news('AAPL', max_pages=5)
print(f"Scraped {len(articles)} articles")
```

## ğŸ”„ Import into Other Projects

The modular design makes it easy to import utilities:

```python
# In your external project
from sentiment_delta.utils import get_logger, MongoDBManager
from sentiment_delta.data import process_ticker_data

logger = get_logger(__name__)
data = process_ticker_data('TSLA')
```

## âš™ï¸ Configuration Options

| Environment Variable | Description                 | Default              |
| -------------------- | --------------------------- | -------------------- |
| `MONGODB_URI`        | MongoDB connection string   | Required             |
| `DATABASE_NAME`      | Database name               | `stock_market_db`    |
| `TICKERS`            | Comma-separated ticker list | `AAPL,GOOGL,MSFT...` |
| `LOG_LEVEL`          | Logging level               | `INFO`               |
| `BATCH_SIZE`         | Database batch size         | `1000`               |
| `SCRAPING_MAX_PAGES` | Max pages per ticker        | `10`                 |

## ğŸ“Š Pipeline Outputs

### Stock Data Pipeline

- Downloads hourly stock data for configured tickers
- Stores in MongoDB collections (one per ticker)
- Creates performance indexes
- Provides execution summary

### News Scraping Pipeline

- Scrapes financial news articles
- Extracts article content and metadata
- Creates text embeddings for vector search
- Stores in MongoDB with sentiment data

## ğŸ› ï¸ Key Improvements

### From Original Code:

- âœ… **Modular Structure**: Separated concerns into logical modules
- âœ… **DRY Principle**: Eliminated duplicate MongoDB and logging code
- âœ… **KISS Principle**: Simplified complex functions into smaller utilities
- âœ… **Reusable Logger**: Centralized logging configuration
- âœ… **Unified Database**: Consolidated MongoDB operations
- âœ… **Environment Config**: Support for environment variables
- âœ… **Error Handling**: Consistent error logging and handling
- âœ… **Type Hints**: Added type annotations for better code clarity
- âœ… **Documentation**: Comprehensive docstrings and examples

### Benefits:

- **Maintainability**: Easy to modify and extend individual components
- **Testability**: Each module can be tested independently
- **Reusability**: Import utilities into other projects easily
- **Scalability**: Add new data sources or processors without affecting existing code
- **Debugging**: Clear separation makes issues easier to trace

## ğŸ“ Example Integration

```python
# example_external_project.py
import pandas as pd
from sentiment_delta import get_config, get_logger, create_mongodb_manager
from sentiment_delta.data import process_ticker_data

def my_analysis_function():
    # Setup
    config = get_config()
    logger = get_logger(__name__)

    # Get data
    data = process_ticker_data('AAPL')

    # Your analysis logic here
    analysis_result = data.describe()

    return analysis_result
```

This refactored structure provides a solid foundation for building sophisticated financial analysis tools while maintaining clean, readable, and maintainable code.
